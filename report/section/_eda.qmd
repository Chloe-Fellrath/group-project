# EDA

## Univariate Analysis
In this step, each key variable is examined individually to understand its distribution, central tendency, and overall spread. This approach helps us identify important characteristics such as skewness, outliers, common categories, and temporal patterns.
By analyzing variables one at a time, we gain a clearer view of how each behaves independently before exploring relationships between them. For our project, we focus on four main variables—track_popularity, genre, gender, and release_year—as they form the foundation of our subsequent analyses.
Examining these variables separately allows us to highlight meaningful patterns, detect irregularities, and better justify the methodological choices we make in the later stages of the study.
```{python}
##Loading the data set for an overview of the dataset
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

sns.set_theme(style="whitegrid", context="notebook",
                palette="colorblind", font_scale=1.1")

df = pd.read_csv("cleaned_final_dataset.csv")

df.head() # shows the first 5 rows of the dataset
df.tail() # shows the 5 last rows preview
df.shape # shows the dimension of the dataset
df.dtypes # check the structure of the data
df.isna().sum() # check if there is some missing value (no missing values found)
```
Since the dataset is complete, we can proceed directly with feature-level analysis and explore patterns in musical characteristics.
## Overview of the key variables
To recall we have chosen 4 key variables that will help us through our analysis:
- track_popularity: integer
- genre: string
- gender: string
- release_year: integer

## Distribution Plots
### Distribution of popularity
```{python}
#| label: fig-performance-dist
#| fig-cap: "Distribution of performance scores showing approximately normal distribution"
# Set publication-quality style
sns.set_theme(style="whitegrid", context="notebook",
              palette="colorblind", font_scale=1.1)
plt.figure(figsize=(10,5))
sns.histplot(df["track_popularity"], kde=True, bins=30)
plt.title("Distribution of track popularity scores")
plt.xlabel("Popularity")
plt.ylabel("Count")
plt.show()
```
The distribution of track popularity is noticeably right-skewed, as shown in the histogram. Although our dataset focuses on songs that were considered popular (Billboard Hot year-end charts) from the 1960s to today, many tracks now receive very low popularity scores (between 0 and 10).
This pattern reflects how Spotify calculates popularity: it is not based on historical success, but on current listening activity. As a result, older tracks that were once widely recognized may no longer be frequently streamed, leading to low popularity values today.
This skewness highlights an important limitation of the variable: popularity on Spotify captures present-day relevance, not long-term cultural impact. This will be important to consider when interpreting trends over time or comparing older and newer releases.
### Distribution of genre
```{python}
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv("../data/processed/cleaned_final_dataset.csv")

def map_genre(genre):
    if pd.isna(genre) or str(genre).strip().lower() in ["n/a", "unknown", ""]:
        return None  # Remove unknowns
    if "rock" in genre:
        return "Rock"
    if "pop" in genre or "christmas" in genre:
        return "Pop"
    if "hip hop" in genre or "hip-hop" in genre or "rap" in genre:
        return "Hip-Hop/Rap"
    if "edm" in genre or "electronic" in genre or "electro" in genre or "new wave" in genre or "synth" in genre:
        return "Electronic/Synth"
    if "jazz" in genre or "motown" in genre or "northern soul" in genre or "new jack swing" in genre:
        return "Jazz"
    if "metal" in genre:
        return "Metal"
    if "folk" in genre or "country" in genre:
        return "Country"
    if "r&b" in genre or "soul" in genre or "doo-wop" in genre or "doowop" in genre:
        return "R&B/Soul"
    if "unknown" in genre:
        return "Unknown"
    return "Other"

# Apply grouping
df["genre_grouped"] = df["genre"].apply(map_genre)
# Count frequencies
genre_counts = df["genre_grouped"].value_counts()

plt.figure(figsize=(10, 6))
plt.bar(genre_counts.index, genre_counts.values)   # shows the barplots
plt.xticks(rotation=45, ha="right")
plt.title("Genre Distribution")
plt.xlabel("Genre")
plt.ylabel("Count")
plt.tight_layout()
plt.show()
```
In this plot, all songs with unknown or ambiguous genres have been removed for clearer interpretation. We grouped all genres into the most frequent categories to better understand trends, excluding less common or unclassified genres.
The visualization highlights the most popular genres across decades, showing, for example, the prominence of Rock and the rise of Pop and Hip-Hop/Rap later on, offering interesting analysis insights to look into how music tastes have evolved over time.
### Distribution of gender
The gender distribution contains four categories: male, female, group, non-binary, and unknown. The male and female categories represent individual artists whose gender information is explicitly provided. The unknown category corresponds to missing or incomplete entries, which mainly come from inconsistencies in the MusicBrainz API.
This highlights a data limitation: gender information is not always available for every artist, especially older or less documented ones. The group category refers to musical groups or bands; these may consist of only men, only women, or mixed members. We chose not to classify groups further by internal composition, as this would require additional assumptions and introduce classification uncertainty.
Finally, the non-binary category represents a very small proportion of the dataset. This reflects both the relatively recent visibility of non-binary artists in mainstream music databases and the historical lack of representation in the industry. Overall, this distribution illustrates both structural biases in data collection and broader social dynamics within the music industry.
```{python}
sns.set_theme(style="whitegrid", context="notebook",
              palette="colorblind", font_scale=1.1)
plt.figure(figsize=(8,5))
sns.countplot(data=df, x="gender")
plt.title("Distribution of gender")
plt.xlabel("Gender category")
plt.ylabel("Count")
plt.show()
```
This missing gender information must be acknowledged because it affects the interpretation of all gender-related analyses. Any comparison between male, female, non-binary, and group artists will be biased if ‘unknown’ forms such a large segment.
For this reason, descriptive statistics and statistical tests should be conducted both including and excluding the ‘unknown’ category, depending on the research question.
```{python}
# Filter only men and women
df_binary_gender = df[df["gender"].isin(["male", "female"])]

sns.set_theme(style="whitegrid", context="notebook",
              palette="colorblind", font_scale=1.1)

plt.figure(figsize=(8,5))
sns.countplot(data=df_binary_gender, x="gender")
plt.title("Distribution of Gender (Men vs Women Solo Artists Only)")
plt.xlabel("Gender")
plt.ylabel("Count")
plt.show()
```
For this additional visualization, we filtered the dataset to include only male and female solo-artists in order to observe the distribution between these two majority groups.
Entries labeled “unknown” or “non-binary” were excluded from this plot but are still considered in the global analysis.

###Distribution of the release year
```{python}
plt.figure(figsize=(10,5))
sns.histplot(df["release_year"], bins=5)
plt.title("Distribution of release years")
plt.xlabel("Release year")
plt.ylabel("Count")
plt.show()
```
The distribution of release years shows a clear decline in the number of tracks originating from earlier decades, particularly from the 1960s to the early 1980s. Part of this decline is due to missing values introduced during our standardisation and cleaning process, where inconsistent or non-numeric year formats could not be reliably converted and therefore became “unknown” (represented as 0) in the dataset.
Additionally, Spotify’s API does not always provide a release year for older recordings, especially for tracks that were digitized, reissued, or remastered multiple times. In cases of remastered editions, the available release year may refer to the reissue date rather than the original publication year, creating additional uncertainty in the dataset.
Consequently, the temporal distribution should be interpreted with caution, as the representation of earlier decades is incomplete and may not accurately reflect the true musical output of those periods.
To facilitate clearer temporal analysis, we create a new variable grouping tracks by decade, which smooths out year-to-year inconsistencies.
```{python}
##Distribution of decades
# Create decade variable from release_year
df["decade"] = (df["release_year"] // 10) * 10

# Convert to string labels (e.g., "1960s")
df["decade"] = df["decade"].astype(int).astype(str) + "s"

# Check distribution
df["decade"].value_counts().sort_index()

# Visualization of the plot
plt.figure(figsize=(10,5))
sns.countplot(data=df, x="decade", order=sorted(df["decade"].unique()))
plt.title("Distribution of Tracks by Decade")
plt.xlabel("Decade")
plt.ylabel("Count")
plt.show()
```
::: {.panel-tabset}

## Summary Statistics

```{python}
#| label: tbl-summary-stats
#| tbl-cap: "Summary statistics for performance scores"
# Code visibility controlled by format settings in report.qmd

# Display comprehensive summary statistics
summary_stats = dummy_performance["performance"].describe()
print("\n=== Performance Summary Statistics ===")
print(summary_stats.to_string())

# Additional statistics
print(f"\nSkewness: {dummy_performance['performance'].skew():.3f}")
print(f"Kurtosis: {dummy_performance['performance'].kurtosis():.3f}")
```

## Box Plot

```{python}
#| label: fig-performance-box
#| fig-cap: "Box plot showing the five-number summary and outliers"
# Code visibility controlled by format settings in report.qmd

fig, ax = plt.subplots(figsize=(6, 4))

# Box plot
bp = ax.boxplot(dummy_performance["performance"], vert=True, patch_artist=True,
                labels=["Performance"],
                boxprops=dict(facecolor='lightblue', edgecolor='black', linewidth=1.5),
                medianprops=dict(color='red', linewidth=2),
                whiskerprops=dict(color='black', linewidth=1.5),
                capprops=dict(color='black', linewidth=1.5))

ax.set_title("Performance Score Distribution (Box Plot)",
             fontsize=13, fontweight='bold', pad=15)
ax.set_ylabel("Performance Score", fontsize=11)
ax.grid(True, axis='y', alpha=0.3, linestyle='--')

plt.tight_layout()
plt.show()
```

:::

## Bivariate Analysis

Explore relationships between two variables.

Our univariate analysis in @fig-performance-dist revealed that performance scores follow an approximately normal distribution with a mean of 0.90. The box plot (@fig-performance-box) confirmed this finding and helped identify a few outliers at the lower end of the distribution.

::: {.callout-tip}
## How to Reference Figures

Use `@fig-label` syntax to reference figures in your text. Quarto automatically numbers them and creates clickable links.

**Examples with figures in this template:**

- `@fig-performance-dist` → See @fig-performance-dist for details
- `@fig-correlation-matrix` → As shown in @fig-correlation-matrix
- `@tbl-anova-test` → The ANOVA results in @tbl-anova-test

**Why reference figures?**

1. Automatic numbering (updates if you reorder)
2. Clickable links in HTML output
3. Professional academic writing standard
4. Helps readers find the relevant visualization

**Example usage in text:**

"The distribution shown in @fig-performance-dist indicates..."

"As seen in @fig-correlation-matrix, there is a strong positive correlation..."
:::

Now let's examine how performance varies across different instructors.

::: {.panel-tabset}

## Grouped Comparison

```{python}
#| label: fig-performance-by-instructor
#| fig-cap: "Performance scores grouped by instructor showing variation across instructors"
# Code visibility controlled by format settings in report.qmd

fig, ax = plt.subplots(figsize=(8, 5))

# Violin plot with individual points
sns.violinplot(data=dummy_performance, x="instructor", y="performance",
               ax=ax, inner="box", palette="Set2", linewidth=1.5,
               edgecolor='black')

# Overlay individual points
sns.swarmplot(data=dummy_performance, x="instructor", y="performance",
              ax=ax, color='black', alpha=0.3, size=3)

# Customize
ax.set_title("Performance Scores by Instructor",
             fontsize=14, fontweight='bold', pad=15)
ax.set_xlabel("Instructor", fontsize=12)
ax.set_ylabel("Performance Score", fontsize=12)
ax.grid(True, axis='y', alpha=0.3, linestyle='--')

plt.tight_layout()
plt.show()
```

## Statistical Test

```{python}
#| label: tbl-anova-test
#| tbl-cap: "ANOVA test results for performance differences across instructors"
# Code visibility controlled by format settings in report.qmd

from scipy import stats

# Group data by instructor
groups = [group["performance"].values
          for name, group in dummy_performance.groupby("instructor")]

# Perform ANOVA
f_stat, p_value = stats.f_oneway(*groups)

print("\n=== ANOVA Test Results ===")
print(f"F-statistic: {f_stat:.4f}")
print(f"P-value: {p_value:.4f}")
print(f"\nInterpretation: {'Significant' if p_value < 0.05 else 'Not significant'} difference at α=0.05")

# Group means
print("\n=== Group Means ===")
print(dummy_performance.groupby("instructor")["performance"].mean().to_string())
```

:::

::: {.callout-important}
## Plot Quality Requirements

Every plot in your report should have:

✓ **Clear title** that explains what's being shown
✓ **Labeled axes** with units when applicable
✓ **Legend** if multiple groups/series are shown
✓ **Appropriate color scheme** (colorblind-friendly)
✓ **Proper sizing** (readable text, not too small/large)
✓ **Figure caption** using `fig-cap` option

**Poor plots = Poor grades!** Take time to make your visualizations publication-quality.
:::

## Correlation Analysis

::: {.panel-tabset}

## Correlation Heatmap

```{python}
#| label: fig-correlation-matrix
#| fig-cap: "Correlation matrix showing relationships between numeric variables"
# Code visibility controlled by format settings in report.qmd

# Create dummy dataset with multiple numeric variables
np.random.seed(42)
n = 200
dummy_data = pd.DataFrame({
    'Age': np.random.randint(20, 60, n),
    'Experience': np.random.randint(0, 30, n),
    'Performance': np.random.normal(0.85, 0.1, n).clip(0, 1),
    'Salary': np.random.normal(60000, 20000, n)
})

# Add some correlations
dummy_data['Salary'] = 40000 + dummy_data['Experience'] * 1000 + np.random.normal(0, 5000, n)
dummy_data['Performance'] = 0.6 + dummy_data['Experience'] * 0.01 + np.random.normal(0, 0.1, n)
dummy_data['Performance'] = dummy_data['Performance'].clip(0, 1)

# Calculate correlation matrix
corr_matrix = dummy_data.corr()

# Create heatmap
fig, ax = plt.subplots(figsize=(7, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,
            square=True, linewidths=1, cbar_kws={"shrink": 0.8},
            fmt='.3f', ax=ax, vmin=-1, vmax=1)

ax.set_title("Correlation Matrix of Numeric Variables",
             fontsize=14, fontweight='bold', pad=15)

plt.tight_layout()
plt.show()
```

## Scatter Plot

```{python}
#| label: fig-scatter-experience-performance
#| fig-cap: "Scatter plot showing positive relationship between experience and performance"
# Code visibility controlled by format settings in report.qmd

fig, ax = plt.subplots(figsize=(8, 5))

# Scatter plot with regression line
sns.regplot(data=dummy_data, x='Experience', y='Performance',
            ax=ax, scatter_kws={'alpha': 0.5, 's': 50, 'edgecolor': 'black'},
            line_kws={'color': 'red', 'linewidth': 2})

ax.set_title("Experience vs Performance",
             fontsize=14, fontweight='bold', pad=15)
ax.set_xlabel("Years of Experience", fontsize=12)
ax.set_ylabel("Performance Score", fontsize=12)
ax.grid(True, alpha=0.3, linestyle='--')

# Add correlation coefficient
corr = dummy_data['Experience'].corr(dummy_data['Performance'])
ax.text(0.05, 0.95, f'Correlation: {corr:.3f}',
        transform=ax.transAxes, fontsize=11,
        verticalalignment='top',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.show()
```

:::

## Key Findings

**Remember: Interpretation is more important than the plots themselves!** Each finding below not only states *what* we observe but also *why* it matters and *what* it means for our analysis.

Summarize the main insights from your exploratory analysis. **Always reference your figures when discussing findings and provide thorough interpretation!**

1. **Distribution patterns**: The performance scores shown in @fig-performance-dist follow an approximately normal distribution with a mean of `{python} f'{dummy_performance["performance"].mean():.2f}'` and standard deviation of `{python} f'{dummy_performance["performance"].std():.2f}'`.

   **Interpretation**: This normal distribution suggests that most students perform around the average, with fewer students at the extremes (very high or very low scores). The relatively small standard deviation indicates consistent performance across the group. This pattern is typical in educational settings and suggests that the assessment was well-calibrated meaning not too easy (which would cause ceiling effects) nor too difficult (which would cause floor effects). The normality assumption also validates the use of parametric statistical tests for subsequent analyses.

2. **Outliers and data quality**: The box plot (@fig-performance-box) reveals minimal outliers, with only a few observations falling below the lower whisker.

   **Interpretation**: The scarcity of outliers suggests good data quality and consistent measurement. The few low-performing outliers warrant further investigation - they could represent students who faced unusual circumstances or measurement errors. However, their small number means they are unlikely to significantly impact our overall conclusions. This finding gives us confidence in proceeding with the full dataset without extensive outlier removal.

3. **Group differences**: @fig-performance-by-instructor demonstrates noticeable variation in performance across different instructors, with some instructors showing higher median scores than others. The ANOVA test (@tbl-anova-test) confirms these differences are `{python} 'statistically significant (p < 0.05)' if p_value < 0.05 else 'not statistically significant (p ≥ 0.05)'`.

   **Interpretation**: `{python} 'The significant differences across instructors raise important questions about teaching effectiveness, grading consistency, or student assignment to sections. This finding suggests that "instructor" should be included as a control variable in any regression models predicting performance.' if p_value < 0.05 else 'The lack of significant differences suggests that instructor assignment does not substantially impact performance, or that grading standards are well-harmonized across sections.'` It also indicates that comparing students across different sections requires careful consideration. From a policy perspective, this might warrant investigating whether certain teaching methods are more effective or whether grading standards need to be harmonized across sections.

4. **Relationships**: The correlation matrix (@fig-correlation-matrix) reveals several interesting patterns:
   - Strong positive correlation (r = `{python} f'{corr_matrix.loc["Experience", "Salary"]:.2f}'`) between Experience and Salary
   - Moderate positive correlation (r = `{python} f'{corr_matrix.loc["Experience", "Performance"]:.2f}'`) between Experience and Performance
   - Weak correlation (r = `{python} f'{corr_matrix.loc["Age", "Performance"]:.2f}'`) between Age and Performance

   **Interpretation**: The Experience-Salary correlation aligns with economic theory that experience is rewarded in labor markets. The Experience-Performance correlation suggests that experience contributes to better performance, though other factors clearly matter as well. Interestingly, Age shows minimal correlation with Performance, suggesting that chronological age alone doesn't predict success - what matters is relevant experience. These patterns will guide our variable selection for predictive modeling, favoring Experience over Age as a key predictor.

5. **Experience-Performance relationship**: @fig-scatter-experience-performance clearly shows a positive linear relationship, with more experienced individuals tending to have higher performance scores. The correlation coefficient is `{python} f'{corr:.2f}'`.

   **Interpretation**: The linear relationship visible in the scatter plot confirms that experience has a consistent, positive effect on performance. However, the substantial scatter around the regression line indicates that experience alone doesn't determine performance - individual differences and other factors play important roles. This suggests that while experience is valuable, organizations shouldn't rely solely on it when making hiring or promotion decisions.

::: {.callout-warning}
## Common Mistakes in Interpretation

**Observation (not interpretation):** "The histogram shows a normal distribution."
**Why it's insufficient:** This only describes what you see - it's an observation, not an interpretation. You need to explain what it *means* and *why it matters*.

**Good interpretation (observation + story):** "The histogram shows a normal distribution (mean = 0.90, sd = 0.05), which indicates consistent performance across students. This pattern validates the use of parametric statistical tests in our subsequent analysis. The tight distribution suggests the assessment was well-calibrated, effectively distinguishing between ability levels without ceiling or floor effects that would compress scores."

**Remember:**

- **Observation** = What you see in the data/plot
- **Interpretation** = The story behind it - what it means, why it matters, what implications it has
- **Always do both!** State the observation, then interpret its significance.
:::

::: {.callout-warning}
## Common Mistake: Not Referencing Figures

**Bad:** "The histogram shows a normal distribution."
**Good:** "As shown in @fig-performance-dist, the histogram reveals a normal distribution."

**Why?**

- Helps readers locate the relevant visualization
- Creates professional, academic-style writing
- Enables automatic figure numbering and links
:::

::: {.callout-tip}
## From EDA to Analysis

Use your EDA findings to:

- **Refine research questions** based on observed patterns
- **Select appropriate statistical methods** based on data distributions
- **Identify variables** for inclusion in models
- **Justify transformations** (e.g., log transform for skewed data)
- **Set expectations** for what you might find in formal analysis
:::
